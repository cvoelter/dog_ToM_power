---
title: "Study 5 - binomial GLMM - Power analysis"
author: "Christoph VÃ¶lter"
date: "08/04/2022"
output: 
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(tidyverse)
library(cowplot)
library("gghalves")
library(ggthemes)

#load(".RData")
```

## Generate data



```{r echo=FALSE, include=FALSE}
set.seed(100)
n.subject <- 32 # number subjects
n.per.subject <- 8 # observations per subject
n.per.condition <- 4 # observations per subject and condition
n.blocks <- 4
age_range <- c(12:130) # age range between 1 and 13 years
fb.per<-c(0.5, 0.6)
tb.per<-c(0.1, 0.2)

subj.id <- as.factor(paste("subj", str_pad(1:n.subject, 2, pad = "0"), sep = "."))

order_possibilities<-as.factor(c("fb-tb", "tb-fb", "fb-tb", "tb-fb"))

block_order <- as.vector(replicate(n.subject, sample(x =order_possibilities, size = 4, replace = F)))

start.data <- data.frame(subj.id)
# duplicate rows according to the number obs. per subject:
start.data <- start.data[rep(x = 1:nrow(start.data), times = n.per.subject), ]
start.data <- as.data.frame(start.data)
names(start.data) <- "subj.id"

# add condition and trial number
start.data <- data.frame(expand.grid(subj.id = subj.id, phase = c("test_phase"), block = c(1:n.per.condition)))%>%
  arrange(subj.id, block)

start.data$block_order <- block_order

start.data<- start.data%>%
  separate(block_order, c("1", "2"), sep = "-")%>%
  pivot_longer(cols="1":"2", names_to = "trial_w_block", values_to = "condition")

start.data$trial <- rep(1:8,n.subject)
start.data$sex <- rep(c(rep("m", 8), rep("f", 8)), n.subject/2)
# z-transformation of covariates
start.data$z.trial <- as.vector(scale(as.numeric(start.data$trial)))


# dummy code factors
start.data$condition <- as.factor(start.data$condition)
start.data$condition.dummy <- as.numeric(start.data$condition == levels(start.data$condition)[2])


# center condition for random slopes:
start.data$condition.c <- as.numeric(start.data$condition) - mean(as.numeric(start.data$condition))

table(start.data$trial, start.data$condition)
table(start.data$block, start.data$condition)
```

## Simulation

```{r eval=FALSE, include=FALSE}
n.simus <- 1000 # small number for testing
r.effects <- c(0.40) # random effects to be simulated
# with the intercept being 0.4054651 (qlogis(0.4)) we assume a moderately large random intercept of 1.386294.

r.slope.tb <- c(1.8)
# with the estimate being -1.791759 (qlogis(0.4)-qlogis(0.1)) we assume a moderately large random slope of 1.8.

r.slope.trial <- 0.2

# create object to store the simulation parameters and results:
all.res <- data.frame(expand.grid(
  n.per.subject = n.per.subject, r.effect = r.effects,
  r.slope.tb = r.slope.tb, r.slope.trial = r.slope.trial,
  fb.per = fb.per,
  tb.per = tb.per,
  simu = 1:n.simus
))
all.res$icpt <- NA
all.res$conditiontb <- NA
all.res$re.sd <- NA
all.res$warns.full <- NA
all.res$warns.null <- NA
all.res$lrt.p.con <- NA
#all.res$lrt.p.age <- NA
all.res$full.null.p <- NA

all.ests <- matrix(NA, nrow = n.simus, ncol = 1)
colnames(all.ests) <- c("lrt.p.con")

# create data frame with design:
## done above

# load packages needed:
library(lme4)
# Loading required package: Matrix
library(kyotil) # we want to store info about convergence issues

# define control structure to make convergence more likely:
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))

xdata <- start.data


# run simulation
for (i in 1:nrow(all.res)) {

  set.seed(i) # allows to later replicate individual simulations

  # add age  (if it should be generated in each loop)
  age <- sample(x = age_range, size = length(unique(xdata$subj.id)), replace = T)
  xdata$age <- as.numeric(age[as.numeric(xdata$subj.id)])
  xdata$z.age <- scale(xdata$age)
  m.mat <- model.matrix(object = ~condition + z.age + sex + z.trial , data = xdata) # create model martix

  coefs <- c(
    "(Intercept)" = qlogis(all.res[i, "fb.per"]),
    "conditiontb" = log(all.res[i, "tb.per"] / (1 - all.res[i, "tb.per"])) - log(all.res[i, "fb.per"] / (1 - all.res[i, "fb.per"])),
  "z.age" = 0,
  "sexm" = 0,
  "z.trial" = 0
  )

  LP <- m.mat[, names(coefs)] %*% coefs # LP wrt fixed effects

  # add random effect to linear predictor:
  LP <- LP + rnorm(n = n.subject, sd = all.res[i, "r.effect"])[as.numeric(xdata$subj.id)] +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.tb"])[as.numeric(xdata$subj.id)] * xdata$condition.dummy +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.trial"])[as.numeric(xdata$subj.id)] * xdata$z.trial 

  # generate response:
  xdata$correct <- rbinom(n = nrow(xdata), size = 1, prob = exp(LP) / (1 + exp(LP)))


  # fit full model:
  full <- keepWarnings(glmer(correct ~ condition+ z.trial + (1 + condition.c + z.trial | subj.id),
    data = xdata, family = binomial, control = contr
  ))

  # store results:
  all.res[i, c("icpt", "conditiontb", "z.trial")] <- fixef(full$value)
  all.res[i, "re.sd"] <- as.data.frame(summary(full$value)$varcor)[1, "sdcor"]
  all.res[i, "warns.full"] <- nchar(paste(full$warnings, collapse = ""))
  all.res[i, "lrt.p.con"] <- as.data.frame(drop1(full$value, test = "Chisq"))["condition", "Pr(Chi)"]
    all.res[i, "lrt.trial.p"] <- as.data.frame(drop1(full$value, test = "Chisq"))["z.trial", "Pr(Chi)"]
    print(i)
}

save.image("Study5_power_sim_binomial_GLMM.RData")
```

## Evaluation of results 

* number of warning per combinations of random effects (out of 1000 models per cell)  
Full model:  
```{r echo=FALSE}
#full model
tapply(X=all.res[, "warns.full"]>0, INDEX=all.res[, c("r.slope.tb", "r.effect")],
FUN=sum)
#warning codes: 
#363: unable to evaluate scaled gradient. Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
#205: Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?
```


## Only models that converged are evaluated from here on:  

```{r include=FALSE}
all.res2=subset(all.res, warns.full==0)
```


### How many models converged, have a significant full-null model comparison, and a significant LRT of condition?  
```{r echo=FALSE}
n.converged<- all.res2%>%
    group_by(tb.per,fb.per, r.effect, r.slope.tb ) %>%
  summarise(n.converged=length(lrt.p.con))


lrt.data2 <- all.res2 %>%
  #filter(full.null.p<0.05)%>%
  group_by(tb.per, fb.per, r.effect, r.slope.tb ) %>%
  summarise(lrt.p.con.median = median(lrt.p.con), 
            lrt.p.trial.median = median(lrt.trial.p),
            n.sign.lrt.con = length(lrt.p.con[lrt.p.con < 0.05]),
            n.sign.lrt.trial = length(lrt.trial.p[lrt.trial.p < 0.05]),
            n.lrt = n.simus,
            proportion.sign.lrt.con = length(lrt.p.con[lrt.p.con < 0.05]) / n.simus,
            proportion.sign.lrt.trial = length(lrt.trial.p[lrt.trial.p < 0.05]) / n.simus)%>%
  full_join(n.converged)

lrt.data2
```

#### Plotting the proportion of significant LRTs for the predictor variable condition ONLY based on models that converged and with a significant full-null model comparison

```{r echo=FALSE}
p.con.power <- ggplot(data = lrt.data2, aes(x= as.factor(tb.per),y = proportion.sign.lrt.con, fill=as.factor(fb.per))) +
  geom_bar(stat="identity", color="black", position=position_dodge())+
  scale_y_continuous(breaks=seq(0,1,0.2), limits=c(0, 1))+
  geom_hline(yintercept = 0.8, colour = "black", lwd = 1.1, lty = 2) +
   # geom_hline(yintercept = 0.05, colour = "darkgrey", lwd = 1.1, lty = 4) +
  scale_fill_manual(values=c("dodgerblue", "darkorange", "darkgrey"))+
  labs(fill = "FB condition", y="Power", x= "True belief condition") +
  theme_few()#+
  #theme(legend.position="none")
p.con.power

ggsave(p.con.power, filename = "Study5_power_sim.png", scale = 0.7, height = 5, width = 8)
```
